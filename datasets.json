[
    {
      "name": "XAI-FUNGI",
      "type": "qualitative / quantitative",
      "description": "XAI-FUNGI is a dataset designed to evaluate explainable AI methods in the context of fungal species classification. It includes images of fungal species along with their corresponding labels and explanations for model predictions.",
      "storage_folder": "DS_XAI_FUNGI",
      "inner_path": "xai-fungi-main/data/explanations.csv",
      "link": "https://zenodo.org/api/records/15222484/files-archive",
      "field_mapping": {
        "question_fields": ["image_path", "prediction"],
        "answer_field": "explanation",
        "question_template": "Image: {image_path}\nPredicted class: {prediction}\nExplain why this prediction was made.",
        "id_field": "sample_id"
      },
      "compatible_prompts": ["fungi_v1_basic", "fungi_v2_detailed", "general_explanation"],
      "task_type": "image_classification_explanation",
      "evaluation_metrics": ["semantic_similarity", "explanation_completeness", "scientific_accuracy"]
    },

    {
      "name": "GMEG-EXP",
      "type": "qualitative",
      "description": "A Dataset of Human and LLM-Generated Explanations of Grammatical and Fluency Edits",
      "storage_folder": "DS_GMEG_EXP",
      "inner_path": "gmeg-exp-main/data/3_annotated_data/full-scale_data/full_scale_annotated_full.csv",
      "link": "https://github.com/grammarly/gmeg-exp/archive/refs/heads/main.zip",
      "field_mapping": {
        "question_fields": ["original", "revised"],
        "answer_field": "please_explain_the_revisions_write_na_if_not_annotatable",
        "question_template": "Original Text: {original}\n\nRevised Text: {revised}",
        "id_field": "id"
      },
      "compatible_prompts": ["gmeg_v1_basic", "gmeg_v2_enhanced", "gmeg_v3_detailed", 
                            "gmeg_v4_minimal", "gmeg_v5_pedagogical", "gmeg_v6_formal",
                            "gmeg_v7_casual", "gmeg_v8_comparative", "gmeg_few_shot"],
      "task_type": "text_correction_explanation",
      "evaluation_metrics": ["bullet_point_ratio", "correction_terminology_recall", "structural_format_match"]
    },

    {
      "name": "HateBRXplain",
      "type": "quantitative",
      "description": "HateBRXplain is a dataset for hate speech detection in Brazilian Portuguese, providing annotated examples of hate speech along with explanations for model predictions.",
      "storage_folder": "DS_HateBRXplain",
      "inner_path": "HateBR-main/data/hatebr_explanations.csv",
      "link": "https://github.com/franciellevargas/HateBR/archive/refs/heads/main.zip",
      "field_mapping": {
        "question_fields": ["text"],
        "answer_field": "explanation",
        "question_template": "Text: {text}\nClassification: Hate Speech\nExplain why this text is classified as hate speech.",
        "id_field": "id"
      },
      "compatible_prompts": ["hate_speech_v1", "hate_speech_detailed", "general_classification"],
      "task_type": "hate_speech_explanation",
      "evaluation_metrics": ["semantic_similarity", "bias_detection", "explanation_clarity"]
    },

    {
      "name": "ExplanationHardness",
      "type": "qualitative",
      "description": "A dataset that provides a collection of explanations for various tasks, focusing on the hardness of explanations in terms of their complexity and interpretability.",
      "storage_folder": "DS_ExplainationHardness",
      "inner_path": "ExplanationHardness-main/data/hardness_explanations.csv",
      "link": "https://github.com/swarnaHub/ExplanationHardness/archive/refs/heads/main.zip",
      "field_mapping": {
        "question_fields": ["input_text", "task_description"],
        "answer_field": "human_explanation",
        "question_template": "Task: {task_description}\nInput: {input_text}",
        "id_field": "example_id"
      },
      "compatible_prompts": ["hardness_v1", "hardness_detailed", "general_explanation"],
      "task_type": "explanation_complexity_analysis",
      "evaluation_metrics": ["complexity_score", "interpretability_rating", "semantic_similarity"]
    },
    
    {
      "name": "ReframingHumanAI",
      "type": "qualitative", 
      "description": "A dataset that includes human and AI-generated explanations for various tasks, focusing on how explanations can be reframed to improve understanding and usability.",
      "storage_folder": "DS_ReframingHumanAI",
      "inner_path": "few_shot_explanations-main/data/reframing_data.csv",
      "link": "https://github.com/allenai/few_shot_explanations/archive/refs/heads/main.zip",
      "field_mapping": {
        "question_fields": ["premise", "hypothesis"],
        "answer_field": "explanation",
        "question_template": "Premise: {premise}\nHypothesis: {hypothesis}\nExplain the relationship between these statements.",
        "id_field": "pair_id"
      },
      "compatible_prompts": ["reframing_v1", "reframing_detailed", "general_explanation"],
      "task_type": "explanation_reframing",
      "evaluation_metrics": ["clarity_improvement", "semantic_similarity", "reframing_effectiveness"]
    }
  ]