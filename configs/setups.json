{
  "gmeg": {
    "description": "LLM explanation generation benchmark based on Grammarly's My Edit Graph (GMEG) dataset, which includes human-annotated explanations for text revisions.",
    "dataset": {
      "download_link": "https://github.com/grammarly/gmeg-exp/archive/refs/heads/main.zip",
      "download_path": "DS_GMEG_EXP",
      "csv_file": "gmeg-exp-main/data/3_annotated_data/full-scale_data/full_scale_annotated_full.csv"
    },
    "prompt_fields": {
      "question_fields": ["aligned"],
      "answer_field": "please_explain_the_revisions_write_na_if_not_annotatable"
    },
    "prune_row": {
      "please_explain_the_revisions_write_na_if_not_annotatable": [""]
    },
    "custom_metrics": {
      "module_path": "custom_metrics.gmeg_metrics",
      "metrics_registry": "GMEG_METRICS"
    }
  },
  
  "RHAI_1": {
    "description": "Evaluates the ability of models to generate human-like explanations for various tasks, focusing on the reframing of explanations to enhance clarity and understanding.",
    "dataset": {
      "download_link": "https://github.com/allenai/few_shot_explanations/archive/refs/heads/main.zip",
      "download_path": "DS_ReframingHumanAI",
      "csv_file": "few_shot_explanations-main/data/handwritten_cose_v1.11_examples.csv"
    },
    "prompt_fields": {
      "question_fields": ["question", "choices", "answer"],
      "answer_field": "our_explanation"
    }
  },
  "RHAI_2": {
    "description": "Evaluates the ability of models to select the correct answer from multiple choices for various tasks, focusing on understanding and reasoning.",
    "dataset": {
      "download_link": "https://github.com/allenai/few_shot_explanations/archive/refs/heads/main.zip",
      "download_path": "DS_ReframingHumanAI", 
      "csv_file": "few_shot_explanations-main/data/handwritten_cose_v1.11_examples.csv"
    },
    "prompt_fields": {
      "question_fields": ["question", "choices"],
      "answer_field": "answer"
    }
  },


  "ecqa_choice": {
    "description": "Choice selection for ECQA commonsense questions",
    "dataset": {
      "download_link": "https://huggingface.co/datasets/yangdong/ecqa/resolve/main/data/train-00000-of-00001.parquet?download=true",
      "download_path": "DS_ECQA", 
      "parquet_file": "train-00000-of-00001.parquet"
    },
    "prompt_fields": {
      "question_fields": ["q_concept", "q_text", "q_op1", "q_op2", "q_op3", "q_op4", "q_op5"],
      "answer_field": "q_ans"
    }
  },
  "ecqa_positive": {
    "description": "Generate positive properties explaining correct answer",
    "dataset": {
      "download_link": "https://huggingface.co/datasets/yangdong/ecqa/resolve/main/data/train-00000-of-00001.parquet?download=true", 
      "download_path": "DS_ECQA",
      "parquet_file": "train-00000-of-00001.parquet"
    },
    "prompt_fields": {
      "question_fields": ["q_text", "q_op1", "q_op2", "q_op3", "q_op4", "q_op5", "q_ans"],
      "answer_field": "taskA_pos"
    }
  },
  "ecqa_negative": {
    "description": "Generate negative properties explaining why other choices are wrong",
    "dataset": {
      "download_link": "https://huggingface.co/datasets/yangdong/ecqa/resolve/main/data/train-00000-of-00001.parquet?download=true",
      "download_path": "DS_ECQA", 
      "parquet_file": "train-00000-of-00001.parquet"
    },
    "prompt_fields": {
      "question_fields": ["q_text", "q_op1", "q_op2", "q_op3", "q_op4", "q_op5", "q_ans"],
      "answer_field": "taskA_neg"
    }
  },
  "ecqa_freeflow": {
    "description": "Generate complete free-form explanation", 
    "dataset": {
      "download_link": "https://huggingface.co/datasets/yangdong/ecqa/resolve/main/data/train-00000-of-00001.parquet?download=true",
      "download_path": "DS_ECQA",
      "parquet_file": "train-00000-of-00001.parquet" 
    },
    "prompt_fields": {
      "question_fields": ["q_text", "q_op1", "q_op2", "q_op3", "q_op4", "q_op5", "q_ans"],
      "answer_field": "taskB"
    }
  },


  "hatebrxplain": {
    "download_link": "https://github.com/franciellevargas/HateBR/archive/refs/heads/main.zip",
    "download_path": "DS_HateBRXplain",
    "csv_file": "",
    "question_fields": [],
    "answer_field": "",
    "description": "HateBRXplain is a dataset for hate speech detection in Brazilian Portuguese, providing annotated examples of hate speech along with explanations for model predictions."
  },
  "explainationhardness": {
    "download_link": "https://github.com/swarnaHub/ExplanationHardness/archive/refs/heads/main.zip",
    "download_path": "DS_ExplainationHardness",
    "csv_file": "",
    "question_fields": [],
    "answer_field": "",
    "description": "A dataset that provides a collection of explanations for various tasks, focusing on the hardness of explanations in terms of their complexity and interpretability."
  }
}